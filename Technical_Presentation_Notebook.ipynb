{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf  \n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import tensorflow_addons.layers as layers\n",
    "\n",
    "\n",
    "from gym import spaces\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "try:\n",
    "    xrange = xrange\n",
    "except:\n",
    "    xrange = range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.read_csv('./osi_pca_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>PC14</th>\n",
       "      <th>PC15</th>\n",
       "      <th>PC16</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.104711</td>\n",
       "      <td>0.115576</td>\n",
       "      <td>-0.395859</td>\n",
       "      <td>-0.367811</td>\n",
       "      <td>0.792326</td>\n",
       "      <td>0.687524</td>\n",
       "      <td>-0.413624</td>\n",
       "      <td>0.404863</td>\n",
       "      <td>-0.295999</td>\n",
       "      <td>-0.032112</td>\n",
       "      <td>-0.020025</td>\n",
       "      <td>0.141937</td>\n",
       "      <td>0.128971</td>\n",
       "      <td>-0.100672</td>\n",
       "      <td>-0.406829</td>\n",
       "      <td>0.845749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.142662</td>\n",
       "      <td>-0.271433</td>\n",
       "      <td>-0.129434</td>\n",
       "      <td>0.178537</td>\n",
       "      <td>-0.074198</td>\n",
       "      <td>-0.258909</td>\n",
       "      <td>0.315821</td>\n",
       "      <td>-0.120330</td>\n",
       "      <td>0.054817</td>\n",
       "      <td>0.010389</td>\n",
       "      <td>0.211168</td>\n",
       "      <td>0.171537</td>\n",
       "      <td>0.018455</td>\n",
       "      <td>-0.577434</td>\n",
       "      <td>0.774437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.110375</td>\n",
       "      <td>0.146153</td>\n",
       "      <td>-0.392492</td>\n",
       "      <td>-0.241203</td>\n",
       "      <td>0.771216</td>\n",
       "      <td>0.936403</td>\n",
       "      <td>0.567604</td>\n",
       "      <td>0.373728</td>\n",
       "      <td>-0.208422</td>\n",
       "      <td>-0.012134</td>\n",
       "      <td>-0.036700</td>\n",
       "      <td>0.155926</td>\n",
       "      <td>0.128702</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>-0.345934</td>\n",
       "      <td>0.866735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.034761</td>\n",
       "      <td>0.133210</td>\n",
       "      <td>-0.310407</td>\n",
       "      <td>-0.177025</td>\n",
       "      <td>0.365475</td>\n",
       "      <td>0.202037</td>\n",
       "      <td>-0.171265</td>\n",
       "      <td>0.328262</td>\n",
       "      <td>-0.037567</td>\n",
       "      <td>0.074858</td>\n",
       "      <td>-0.003444</td>\n",
       "      <td>0.192169</td>\n",
       "      <td>0.157149</td>\n",
       "      <td>0.051173</td>\n",
       "      <td>-0.515762</td>\n",
       "      <td>0.798940</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.123149</td>\n",
       "      <td>0.048001</td>\n",
       "      <td>0.711157</td>\n",
       "      <td>-0.095758</td>\n",
       "      <td>0.307547</td>\n",
       "      <td>-0.108562</td>\n",
       "      <td>-0.230177</td>\n",
       "      <td>0.309132</td>\n",
       "      <td>0.017062</td>\n",
       "      <td>0.116845</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.205523</td>\n",
       "      <td>0.176376</td>\n",
       "      <td>0.135875</td>\n",
       "      <td>-0.541553</td>\n",
       "      <td>0.803390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.023538</td>\n",
       "      <td>0.142550</td>\n",
       "      <td>-0.244491</td>\n",
       "      <td>-0.076902</td>\n",
       "      <td>0.053693</td>\n",
       "      <td>-0.219202</td>\n",
       "      <td>-0.229715</td>\n",
       "      <td>0.302661</td>\n",
       "      <td>-0.056145</td>\n",
       "      <td>0.077405</td>\n",
       "      <td>0.014214</td>\n",
       "      <td>0.208672</td>\n",
       "      <td>0.174958</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>-0.546529</td>\n",
       "      <td>0.798287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.183102</td>\n",
       "      <td>0.084289</td>\n",
       "      <td>-0.393380</td>\n",
       "      <td>-0.326629</td>\n",
       "      <td>0.790718</td>\n",
       "      <td>0.774777</td>\n",
       "      <td>-0.155713</td>\n",
       "      <td>0.354513</td>\n",
       "      <td>-0.149013</td>\n",
       "      <td>0.013143</td>\n",
       "      <td>-0.041774</td>\n",
       "      <td>0.523529</td>\n",
       "      <td>0.119604</td>\n",
       "      <td>0.115097</td>\n",
       "      <td>-0.333076</td>\n",
       "      <td>0.805666</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>-0.005150</td>\n",
       "      <td>0.012790</td>\n",
       "      <td>0.571897</td>\n",
       "      <td>-0.358637</td>\n",
       "      <td>0.986430</td>\n",
       "      <td>0.731866</td>\n",
       "      <td>-0.398297</td>\n",
       "      <td>0.403194</td>\n",
       "      <td>-0.096423</td>\n",
       "      <td>0.043948</td>\n",
       "      <td>-0.030007</td>\n",
       "      <td>0.131088</td>\n",
       "      <td>0.136232</td>\n",
       "      <td>-0.075089</td>\n",
       "      <td>-0.399655</td>\n",
       "      <td>0.872121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.151072</td>\n",
       "      <td>0.067793</td>\n",
       "      <td>-0.260093</td>\n",
       "      <td>-0.120412</td>\n",
       "      <td>0.182449</td>\n",
       "      <td>-0.026001</td>\n",
       "      <td>-0.147373</td>\n",
       "      <td>0.247943</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>0.051713</td>\n",
       "      <td>-0.017834</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.171442</td>\n",
       "      <td>-0.022431</td>\n",
       "      <td>-0.433824</td>\n",
       "      <td>0.671264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.045417</td>\n",
       "      <td>0.112371</td>\n",
       "      <td>-0.232892</td>\n",
       "      <td>-0.063361</td>\n",
       "      <td>0.016315</td>\n",
       "      <td>-0.258814</td>\n",
       "      <td>-0.220094</td>\n",
       "      <td>0.264003</td>\n",
       "      <td>-0.062110</td>\n",
       "      <td>0.074123</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.595660</td>\n",
       "      <td>0.171618</td>\n",
       "      <td>0.138461</td>\n",
       "      <td>-0.502776</td>\n",
       "      <td>0.737497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0  0.104711  0.115576 -0.395859 -0.367811  0.792326  0.687524 -0.413624   \n",
       "1  0.000601  0.142662 -0.271433 -0.129434  0.178537 -0.074198 -0.258909   \n",
       "2  0.110375  0.146153 -0.392492 -0.241203  0.771216  0.936403  0.567604   \n",
       "3  0.034761  0.133210 -0.310407 -0.177025  0.365475  0.202037 -0.171265   \n",
       "4 -0.123149  0.048001  0.711157 -0.095758  0.307547 -0.108562 -0.230177   \n",
       "5 -0.023538  0.142550 -0.244491 -0.076902  0.053693 -0.219202 -0.229715   \n",
       "6  0.183102  0.084289 -0.393380 -0.326629  0.790718  0.774777 -0.155713   \n",
       "7 -0.005150  0.012790  0.571897 -0.358637  0.986430  0.731866 -0.398297   \n",
       "8  0.151072  0.067793 -0.260093 -0.120412  0.182449 -0.026001 -0.147373   \n",
       "9  0.045417  0.112371 -0.232892 -0.063361  0.016315 -0.258814 -0.220094   \n",
       "\n",
       "        PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
       "0  0.404863 -0.295999 -0.032112 -0.020025  0.141937  0.128971 -0.100672   \n",
       "1  0.315821 -0.120330  0.054817  0.010389  0.211168  0.171537  0.018455   \n",
       "2  0.373728 -0.208422 -0.012134 -0.036700  0.155926  0.128702  0.008547   \n",
       "3  0.328262 -0.037567  0.074858 -0.003444  0.192169  0.157149  0.051173   \n",
       "4  0.309132  0.017062  0.116845  0.001683  0.205523  0.176376  0.135875   \n",
       "5  0.302661 -0.056145  0.077405  0.014214  0.208672  0.174958 -0.000499   \n",
       "6  0.354513 -0.149013  0.013143 -0.041774  0.523529  0.119604  0.115097   \n",
       "7  0.403194 -0.096423  0.043948 -0.030007  0.131088  0.136232 -0.075089   \n",
       "8  0.247943 -0.057471  0.051713 -0.017834  0.966725  0.171442 -0.022431   \n",
       "9  0.264003 -0.062110  0.074123  0.001389  0.595660  0.171618  0.138461   \n",
       "\n",
       "       PC15      PC16  Revenue  \n",
       "0 -0.406829  0.845749        0  \n",
       "1 -0.577434  0.774437        0  \n",
       "2 -0.345934  0.866735        0  \n",
       "3 -0.515762  0.798940        0  \n",
       "4 -0.541553  0.803390        0  \n",
       "5 -0.546529  0.798287        0  \n",
       "6 -0.333076  0.805666        0  \n",
       "7 -0.399655  0.872121        0  \n",
       "8 -0.433824  0.671264        0  \n",
       "9 -0.502776  0.737497        0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset dummied and scaled in other notebook\n",
    "df = pd.read_csv('./osi_scaled_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Revenue = df.Revenue.apply(lambda x: 1 if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_Jul</th>\n",
       "      <th>Month_June</th>\n",
       "      <th>Month_Mar</th>\n",
       "      <th>Month_May</th>\n",
       "      <th>Month_Nov</th>\n",
       "      <th>Month_Oct</th>\n",
       "      <th>Month_Sep</th>\n",
       "      <th>VisitorType_Other</th>\n",
       "      <th>VisitorType_Returning_Visitor</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026950</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.011536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0        0.000000                      0.0            0.0   \n",
       "1        0.000000                      0.0            0.0   \n",
       "2        0.000000                      0.0            0.0   \n",
       "3        0.000000                      0.0            0.0   \n",
       "4        0.000000                      0.0            0.0   \n",
       "5        0.000000                      0.0            0.0   \n",
       "6        0.000000                      0.0            0.0   \n",
       "7        0.037037                      0.0            0.0   \n",
       "8        0.000000                      0.0            0.0   \n",
       "9        0.000000                      0.0            0.0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0        0.001418                 0.000000   \n",
       "1                     0.0        0.002837                 0.001000   \n",
       "2                     0.0        0.001418                 0.000000   \n",
       "3                     0.0        0.002837                 0.000042   \n",
       "4                     0.0        0.014184                 0.009809   \n",
       "5                     0.0        0.026950                 0.002411   \n",
       "6                     0.0        0.001418                 0.000000   \n",
       "7                     0.0        0.000000                 0.000000   \n",
       "8                     0.0        0.002837                 0.000578   \n",
       "9                     0.0        0.004255                 0.011536   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay  ...  Month_Jul  Month_June  \\\n",
       "0     1.000000   1.000000         0.0         0.0  ...        0.0         0.0   \n",
       "1     0.000000   0.500000         0.0         0.0  ...        0.0         0.0   \n",
       "2     1.000000   1.000000         0.0         0.0  ...        0.0         0.0   \n",
       "3     0.250000   0.700000         0.0         0.0  ...        0.0         0.0   \n",
       "4     0.100000   0.250000         0.0         0.0  ...        0.0         0.0   \n",
       "5     0.078947   0.122807         0.0         0.0  ...        0.0         0.0   \n",
       "6     1.000000   1.000000         0.0         0.4  ...        0.0         0.0   \n",
       "7     1.000000   1.000000         0.0         0.0  ...        0.0         0.0   \n",
       "8     0.000000   0.500000         0.0         0.8  ...        0.0         0.0   \n",
       "9     0.000000   0.111111         0.0         0.4  ...        0.0         0.0   \n",
       "\n",
       "   Month_Mar  Month_May  Month_Nov  Month_Oct  Month_Sep  VisitorType_Other  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0                0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0                0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0                0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0                0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0                0.0   \n",
       "5        0.0        0.0        0.0        0.0        0.0                0.0   \n",
       "6        0.0        0.0        0.0        0.0        0.0                0.0   \n",
       "7        0.0        0.0        0.0        0.0        0.0                0.0   \n",
       "8        0.0        0.0        0.0        0.0        0.0                0.0   \n",
       "9        0.0        0.0        0.0        0.0        0.0                0.0   \n",
       "\n",
       "   VisitorType_Returning_Visitor  Revenue  \n",
       "0                            1.0        0  \n",
       "1                            1.0        0  \n",
       "2                            1.0        0  \n",
       "3                            1.0        0  \n",
       "4                            1.0        0  \n",
       "5                            1.0        0  \n",
       "6                            1.0        0  \n",
       "7                            1.0        0  \n",
       "8                            1.0        0  \n",
       "9                            1.0        0  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaces.box??\n",
    "# spaces.Discrete??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reward_adjustment = 1\n",
    "# Refers to Reward structure. Is imbalance Ratio of classes.\n",
    "# This ratio/reward maybe tuned to improve model Recall\n",
    "lamb_da = (1908/10422) * Reward_adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18307426597582038"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamb_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameEnv(gym.Env):\n",
    " \n",
    "    def __init__(self):\n",
    "        \n",
    "        #Init Action Space with to Discrete steps. 0 or 1, Left or right, On or off.\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        #Init Observation space 26x1 that contain continous values. change shape to fit any dataframe(in theory)\n",
    "        self.observation_space = spaces.Box(-np.inf, np.inf, shape=(26,), dtype=np.float32)\n",
    "        \n",
    "        #Init the rest of DataFrameEnv class variables\n",
    "        self.episode_df = None\n",
    "        self.viewer = None\n",
    "        self.state = None\n",
    "\n",
    "        self.steps_beyond_done = None\n",
    "        self.episode = None\n",
    "        self.test_set_no_labels = None\n",
    "        self.test_labels = None\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset function randomly samples Dataframe, Splits off labels and converts to list\n",
    "        self.episode_df = df.sample(frac=0.8)\n",
    "        self.episode = self.episode_df.drop(columns=['Revenue']).values.tolist()\n",
    "        self.true_labels = self.episode_df['Revenue'].values.tolist()\n",
    "        \n",
    "        try:\n",
    "            # Remove one row from sampled DF \n",
    "            self.state = self.episode.pop()\n",
    "        except:\n",
    "            self.state = None\n",
    "\n",
    "        self.steps_beyond_done = None\n",
    "        # Return to agent as a state.\n",
    "        return np.array(self.state)\n",
    "\n",
    "    \n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action), \"%r (%s) invalid\"%(action, type(action))\n",
    "        \n",
    "        # Pull off next row and assign to state to be returned to agent from this function\n",
    "        state = self.episode.pop()\n",
    "        \n",
    "\n",
    "        done = False\n",
    "        true_label = self.true_labels.pop()\n",
    "        # Compare agents prediction with label and assign reward\n",
    "        \n",
    "        if true_label is not None:\n",
    "            \n",
    "            if (true_label == 1) & (action == true_label):\n",
    "                reward = 1\n",
    "            \n",
    "            elif (true_label == 0) & (action == true_label):\n",
    "                reward = lamb_da\n",
    "            \n",
    "            elif (true_label == 0) & (action != true_label):\n",
    "                reward = -lamb_da\n",
    "            \n",
    "            else:\n",
    "                reward = -1\n",
    "                done = True\n",
    "        else:\n",
    "            reward = 0\n",
    "            done = True\n",
    "        # Return Next state, reward for action in current state and if done/ stop episode.\n",
    "        return np.array(state), reward, done, {}\n",
    "\n",
    "    def validate(self):\n",
    "        # Validation function compare predictions to actuals on test set to build Confusion Matrix\n",
    "        test_set = df[~df.index.isin(self.episode_df.index)]\n",
    "        self.test_set_no_labels = test_set.drop(columns=['Revenue'])\n",
    "        self.test_labels = test_set['Revenue']\n",
    "        \n",
    "        return self.test_set_no_labels, self.test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Environment\n",
    "env = DataFrameEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "H = 52 # number of hidden layer neurons\n",
    "batch_size = 6 # how many episodes before doing a policy update\n",
    "learning_rate = 0.009 # How big/small the steps are in the gradient ascent\n",
    "gamma = 0.99 # discount factor for reward\n",
    "learning_decay = 50 #Learning rate decay (not used currently)\n",
    "D = 26 # input dimensionality\n",
    "total_episodes = 1000 #duhh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(r):\n",
    "    # Calculates a reward to reduce rewards gained towards the end of an episode.\n",
    "    # Not used except for gamma which is used to regulate prioritization of current vs future rewards.\n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_add = 0\n",
    "    for t in reversed(xrange(0, r.size)):\n",
    "        running_add = running_add * gamma + r[t]\n",
    "        discounted_r[t] = running_add\n",
    "    return discounted_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#This defines the network as it goes from taking an observation of the environment to \n",
    "#giving a probability of chosing to the action 0 or 1.\n",
    "observations = tf.compat.v1.placeholder(tf.float32, [None,D] , name=\"input_x\")\n",
    "W1 = tf.compat.v1.get_variable(\"W1\", shape=[D, H],\n",
    "           initializer=tf.initializers.GlorotUniform())\n",
    "# first layer activation function was Tanh for PCA inputs to capture negative value information \n",
    "# changed to relu for modelling on original scaled dataset\n",
    "layer1 = tf.nn.relu(tf.matmul(observations,W1))\n",
    "W11 = tf.compat.v1.get_variable(\"W11\", shape=[H, 8],\n",
    "           initializer=tf.initializers.GlorotUniform())\n",
    "\n",
    "\n",
    "layer11 = tf.nn.relu(tf.matmul(layer1, W11))\n",
    "W2 = tf.compat.v1.get_variable(\"W2\", shape=[8, 1],\n",
    "           initializer=tf.initializers.GlorotUniform())\n",
    "\n",
    "score = tf.matmul(layer11,W2)\n",
    "\n",
    "probability = tf.nn.sigmoid(score)\n",
    "\n",
    "#From here we define the parts of the network needed for learning a good policy.\n",
    "tvars = tf.compat.v1.trainable_variables()\n",
    "input_y = tf.compat.v1.placeholder(tf.float32,[None,1], name=\"input_y\")\n",
    "advantages = tf.compat.v1.placeholder(tf.float32,name=\"reward_signal\")\n",
    "\n",
    "# The loss function. This sends the weights in the direction of making actions \n",
    "# that gave good advantage (reward over time) more likely, and actions that didn't less likely.\n",
    "loglik = tf.compat.v1.log(input_y*(input_y - probability) + (1 - input_y)*(input_y + probability))\n",
    "loss = -tf.reduce_mean(loglik * advantages)\n",
    "\n",
    "newGrads = tf.gradients(loss,tvars)\n",
    "\n",
    "# Once we have collected a series of gradients from multiple episodes, we apply them.\n",
    "# We don't just apply gradeients after every episode in order to account for noise in the reward signal.\n",
    "adam = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate) # Our optimizer\n",
    "W1Grad = tf.compat.v1.placeholder(tf.float32,name=\"batch_grad1\")\n",
    "W11Grad = tf.compat.v1.placeholder(tf.float32,name=\"batch_grad11\")# Placeholders to send the final gradients through when we update.\n",
    "W2Grad = tf.compat.v1.placeholder(tf.float32,name=\"batch_grad2\")\n",
    "batchGrad = [W1Grad,W11Grad,W2Grad]\n",
    "updateGrads = adam.apply_gradients(zip(batchGrad,tvars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stores states, actions, rewards for an episode\n",
    "xs,hs,dlogps,drs,ys,tfps = [],[],[],[],[],[]\n",
    "running_reward = None\n",
    "reward_sum = 0\n",
    "episode_number = 1\n",
    "episode_rewards = []\n",
    "\n",
    "#lists that maybe used to visualise model training/updates\n",
    "policy_gradient = []\n",
    "Q_approx = []\n",
    "loss_list = []\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for episode -1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 0.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 0.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 0.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 0.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 0.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 0.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 0.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 0.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 0.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -2.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -2.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 2.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 0.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -2.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 0.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 0.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 0.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode -2.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 2.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 2.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 2.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 1.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 0.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 5.000000.  Total average reward -1.000000.\n",
      "Average reward for episode 6.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 1.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 7.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 3.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 4.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 2.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 7.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 2.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 0.000000.  Total average reward 0.000000.\n",
      "Average reward for episode -2.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 1.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 9.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 2.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 10.000000.  Total average reward 0.000000.\n",
      "Average reward for episode -1.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 6.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 20.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 2.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 0.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 2.000000.  Total average reward 0.000000.\n",
      "Average reward for episode -1.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 3.000000.  Total average reward 0.000000.\n",
      "Average reward for episode 19.000000.  Total average reward 1.000000.\n",
      "Average reward for episode 7.000000.  Total average reward 1.000000.\n",
      "Average reward for episode 2.000000.  Total average reward 1.000000.\n",
      "Average reward for episode 20.000000.  Total average reward 1.000000.\n",
      "Average reward for episode 10.000000.  Total average reward 1.000000.\n",
      "Average reward for episode 7.000000.  Total average reward 1.000000.\n",
      "Average reward for episode 6.000000.  Total average reward 1.000000.\n",
      "Average reward for episode 3.000000.  Total average reward 1.000000.\n",
      "Average reward for episode 4.000000.  Total average reward 1.000000.\n",
      "Average reward for episode 6.000000.  Total average reward 1.000000.\n",
      "Average reward for episode 10.000000.  Total average reward 1.000000.\n",
      "Average reward for episode 12.000000.  Total average reward 1.000000.\n",
      "Average reward for episode 6.000000.  Total average reward 1.000000.\n",
      "Average reward for episode 32.000000.  Total average reward 2.000000.\n",
      "Average reward for episode 30.000000.  Total average reward 2.000000.\n",
      "Average reward for episode 6.000000.  Total average reward 2.000000.\n",
      "Average reward for episode 8.000000.  Total average reward 2.000000.\n",
      "Average reward for episode 24.000000.  Total average reward 2.000000.\n",
      "Average reward for episode 32.000000.  Total average reward 3.000000.\n",
      "Average reward for episode 13.000000.  Total average reward 3.000000.\n",
      "Average reward for episode 19.000000.  Total average reward 3.000000.\n",
      "Average reward for episode 33.000000.  Total average reward 3.000000.\n",
      "Average reward for episode 38.000000.  Total average reward 3.000000.\n",
      "Average reward for episode 19.000000.  Total average reward 4.000000.\n",
      "Average reward for episode 22.000000.  Total average reward 4.000000.\n",
      "Average reward for episode 51.000000.  Total average reward 4.000000.\n",
      "Average reward for episode 27.000000.  Total average reward 5.000000.\n",
      "Average reward for episode 25.000000.  Total average reward 5.000000.\n",
      "Average reward for episode 42.000000.  Total average reward 5.000000.\n",
      "Average reward for episode 44.000000.  Total average reward 5.000000.\n",
      "Average reward for episode 65.000000.  Total average reward 6.000000.\n",
      "Average reward for episode 55.000000.  Total average reward 7.000000.\n",
      "Average reward for episode 18.000000.  Total average reward 7.000000.\n",
      "Average reward for episode 43.000000.  Total average reward 7.000000.\n",
      "Average reward for episode 18.000000.  Total average reward 7.000000.\n",
      "Average reward for episode 34.000000.  Total average reward 7.000000.\n",
      "Average reward for episode 26.000000.  Total average reward 8.000000.\n",
      "Average reward for episode 33.000000.  Total average reward 8.000000.\n",
      "Average reward for episode 33.000000.  Total average reward 8.000000.\n",
      "Average reward for episode 29.000000.  Total average reward 8.000000.\n",
      "Average reward for episode 33.000000.  Total average reward 9.000000.\n",
      "Average reward for episode 16.000000.  Total average reward 9.000000.\n",
      "Average reward for episode 36.000000.  Total average reward 9.000000.\n",
      "Average reward for episode 16.000000.  Total average reward 9.000000.\n",
      "Average reward for episode 15.000000.  Total average reward 9.000000.\n",
      "Average reward for episode 25.000000.  Total average reward 9.000000.\n",
      "Average reward for episode 15.000000.  Total average reward 9.000000.\n",
      "Average reward for episode 13.000000.  Total average reward 9.000000.\n",
      "Average reward for episode 10.000000.  Total average reward 9.000000.\n",
      "Average reward for episode 13.000000.  Total average reward 9.000000.\n",
      "Average reward for episode 14.000000.  Total average reward 9.000000.\n",
      "Average reward for episode 9.000000.  Total average reward 9.000000.\n",
      "Average reward for episode 19.000000.  Total average reward 10.000000.\n",
      "Average reward for episode 17.000000.  Total average reward 10.000000.\n",
      "Average reward for episode 15.000000.  Total average reward 10.000000.\n",
      "Average reward for episode 20.000000.  Total average reward 10.000000.\n",
      "Average reward for episode 9.000000.  Total average reward 10.000000.\n",
      "Average reward for episode 5.000000.  Total average reward 10.000000.\n",
      "Average reward for episode 13.000000.  Total average reward 10.000000.\n",
      "Average reward for episode 26.000000.  Total average reward 10.000000.\n",
      "Average reward for episode 22.000000.  Total average reward 10.000000.\n",
      "Average reward for episode 22.000000.  Total average reward 10.000000.\n",
      "Average reward for episode 48.000000.  Total average reward 11.000000.\n",
      "Average reward for episode 15.000000.  Total average reward 11.000000.\n",
      "Average reward for episode 13.000000.  Total average reward 11.000000.\n",
      "Average reward for episode 13.000000.  Total average reward 11.000000.\n",
      "Average reward for episode 23.000000.  Total average reward 11.000000.\n",
      "Average reward for episode 11.000000.  Total average reward 11.000000.\n",
      "Average reward for episode 16.000000.  Total average reward 11.000000.\n",
      "Average reward for episode 34.000000.  Total average reward 11.000000.\n",
      "Average reward for episode 28.000000.  Total average reward 11.000000.\n",
      "Average reward for episode 42.000000.  Total average reward 12.000000.\n",
      "Average reward for episode 35.000000.  Total average reward 12.000000.\n",
      "Average reward for episode 56.000000.  Total average reward 12.000000.\n",
      "Average reward for episode 53.000000.  Total average reward 13.000000.\n",
      "Average reward for episode 36.000000.  Total average reward 13.000000.\n",
      "Average reward for episode 38.000000.  Total average reward 13.000000.\n",
      "Average reward for episode 41.000000.  Total average reward 13.000000.\n",
      "Average reward for episode 60.000000.  Total average reward 14.000000.\n",
      "Average reward for episode 44.000000.  Total average reward 14.000000.\n",
      "Average reward for episode 42.000000.  Total average reward 14.000000.\n",
      "Average reward for episode 75.000000.  Total average reward 15.000000.\n",
      "Average reward for episode 40.000000.  Total average reward 15.000000.\n",
      "Average reward for episode 34.000000.  Total average reward 15.000000.\n",
      "Average reward for episode 31.000000.  Total average reward 16.000000.\n",
      "Average reward for episode 22.000000.  Total average reward 16.000000.\n",
      "Average reward for episode 52.000000.  Total average reward 16.000000.\n",
      "Average reward for episode 60.000000.  Total average reward 16.000000.\n",
      "Average reward for episode 28.000000.  Total average reward 17.000000.\n",
      "Average reward for episode 24.000000.  Total average reward 17.000000.\n",
      "Average reward for episode 43.000000.  Total average reward 17.000000.\n",
      "Average reward for episode 45.000000.  Total average reward 17.000000.\n",
      "Average reward for episode 41.000000.  Total average reward 17.000000.\n",
      "Average reward for episode 38.000000.  Total average reward 18.000000.\n",
      "Average reward for episode 19.000000.  Total average reward 18.000000.\n",
      "Average reward for episode 35.000000.  Total average reward 18.000000.\n",
      "Average reward for episode 28.000000.  Total average reward 18.000000.\n",
      "Average reward for episode 28.000000.  Total average reward 18.000000.\n",
      "Average reward for episode 12.000000.  Total average reward 18.000000.\n",
      "Average reward for episode 21.000000.  Total average reward 18.000000.\n",
      "Average reward for episode 49.000000.  Total average reward 18.000000.\n",
      "1001 Episodes completed.\n"
     ]
    }
   ],
   "source": [
    "init = tf.compat.v1.global_variables_initializer()\n",
    "# Launch the graph\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    observation = env.reset() # Obtain an initial observation of the environment\n",
    "\n",
    "    # Reset the gradient placeholder. We will collect gradients in \n",
    "    # gradBuffer until we are ready to update our policy network. \n",
    "    gradBuffer = sess.run(tvars)\n",
    "    for ix,grad in enumerate(gradBuffer):\n",
    "        gradBuffer[ix] = grad * 0\n",
    "    \n",
    "    while episode_number <= total_episodes:\n",
    "        \n",
    "        # Make sure the observation is in a shape the network can handle.\n",
    "        x = np.reshape(observation,[1,D])\n",
    "        \n",
    "        # Run the policy network and get an action to take. \n",
    "        tfprob = sess.run(probability,feed_dict={observations: x})\n",
    "        action = 1 if np.random.uniform() < tfprob else 0\n",
    "        \n",
    "        \n",
    "        xs.append(x) # observation\n",
    "        y = 1 if action == 0 else 0 # a \"fake label\"\n",
    "        ys.append(y)\n",
    "\n",
    "        # step the environment and get new measurements\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "        reward_sum += reward\n",
    "\n",
    "        drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
    "        \n",
    "        \n",
    "        if done: \n",
    "            episode_number += 1\n",
    "            # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
    "            epx = np.vstack(xs)\n",
    "            epy = np.vstack(ys)\n",
    "            epr = np.vstack(drs)\n",
    "            episode_rewards.append(np.sum(drs))\n",
    "            tfp = tfps\n",
    "            xs,hs,dlogps,drs,ys,tfps = [],[],[],[],[],[] # reset array memory\n",
    "\n",
    "            # compute the discounted reward backwards through time\n",
    "            discounted_epr = discount_rewards(epr)\n",
    "            \n",
    "            \n",
    "            # Get the gradient for this episode, and save it in the gradBuffer\n",
    "            tGrad = sess.run(newGrads,feed_dict={observations: epx, input_y: epy, advantages: discounted_epr})\n",
    "            for ix,grad in enumerate(tGrad):\n",
    "                gradBuffer[ix] += grad\n",
    "                \n",
    "            # If we have completed enough episodes, then update the policy network with our gradients.\n",
    "            if episode_number % batch_size == 0: \n",
    "                policy_gradient.append(gradBuffer)\n",
    "                sess.run(updateGrads,feed_dict={W1Grad: gradBuffer[0],W11Grad:gradBuffer[1],W2Grad:gradBuffer[2]})\n",
    "\n",
    "                loss_list.append(loss)\n",
    "                for ix,grad in enumerate(gradBuffer):\n",
    "                    gradBuffer[ix] = grad * 0\n",
    "                \n",
    "                # Give a summary of how well our network is doing for each batch of episodes.\n",
    "                running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "                \n",
    "                print('Average reward for episode %f.  Total average reward %f.' % (reward_sum//batch_size, running_reward//batch_size))\n",
    "                \n",
    "                reward_sum = 0\n",
    "\n",
    "            observation = env.reset()\n",
    "    #get test set with labels. \n",
    "    test_set, test_labels = env.validate()\n",
    "    \n",
    "    for i in test_set.values:\n",
    "        # predict on each test row and append to list\n",
    "        prediction = sess.run(probability, feed_dict={observations:np.reshape(i,[1,D])})\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "            \n",
    "print(episode_number,'Episodes completed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clean = []\n",
    "for i in predictions:\n",
    "    if i < .50:\n",
    "        i = 0\n",
    "        pred_clean.append(i)\n",
    "    else:\n",
    "        i = 1\n",
    "        pred_clean.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_report_1 = classification_report(test_labels,pred_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.19      0.31      2054\n",
      "           1       0.20      1.00      0.33       412\n",
      "\n",
      "    accuracy                           0.32      2466\n",
      "   macro avg       0.60      0.59      0.32      2466\n",
      "weighted avg       0.86      0.32      0.32      2466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cf_report_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_35_reward = confusion_matrix(test_labels,pred_clean,normalize='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4703974 , 0.37793998],\n",
       "       [0.0081103 , 0.14355231]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_35_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cf_3_reward' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-b7a4618bc6e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcf_3_reward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cf_3_reward' is not defined"
     ]
    }
   ],
   "source": [
    "cf_3_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_2_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_report_35 = classification_report(test_labels,pred_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.55      0.71      2092\n",
      "           1       0.28      0.95      0.43       374\n",
      "\n",
      "    accuracy                           0.61      2466\n",
      "   macro avg       0.63      0.75      0.57      2466\n",
      "weighted avg       0.88      0.61      0.67      2466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cf_report_35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from torch.nn import RNN\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m        \n",
       "\u001b[1;32mclass\u001b[0m \u001b[0mRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34mr\"\"\"Applies a multi-layer Elman RNN with :math:`tanh` or :math:`ReLU` non-linearity to an\n",
       "    input sequence.\n",
       "\n",
       "\n",
       "    For each element in the input sequence, each layer computes the following\n",
       "    function:\n",
       "\n",
       "    .. math::\n",
       "        h_t = \\text{tanh}(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n",
       "\n",
       "    where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is\n",
       "    the input at time `t`, and :math:`h_{(t-1)}` is the hidden state of the\n",
       "    previous layer at time `t-1` or the initial hidden state at time `0`.\n",
       "    If :attr:`nonlinearity` is ``'relu'``, then `ReLU` is used instead of `tanh`.\n",
       "\n",
       "    Args:\n",
       "        input_size: The number of expected features in the input `x`\n",
       "        hidden_size: The number of features in the hidden state `h`\n",
       "        num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n",
       "            would mean stacking two RNNs together to form a `stacked RNN`,\n",
       "            with the second RNN taking in outputs of the first RNN and\n",
       "            computing the final results. Default: 1\n",
       "        nonlinearity: The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``\n",
       "        bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
       "            Default: ``True``\n",
       "        batch_first: If ``True``, then the input and output tensors are provided\n",
       "            as `(batch, seq, feature)`. Default: ``False``\n",
       "        dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n",
       "            RNN layer except the last layer, with dropout probability equal to\n",
       "            :attr:`dropout`. Default: 0\n",
       "        bidirectional: If ``True``, becomes a bidirectional RNN. Default: ``False``\n",
       "\n",
       "    Inputs: input, h_0\n",
       "        - **input** of shape `(seq_len, batch, input_size)`: tensor containing the features\n",
       "          of the input sequence. The input can also be a packed variable length\n",
       "          sequence. See :func:`torch.nn.utils.rnn.pack_padded_sequence`\n",
       "          or :func:`torch.nn.utils.rnn.pack_sequence`\n",
       "          for details.\n",
       "        - **h_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
       "          containing the initial hidden state for each element in the batch.\n",
       "          Defaults to zero if not provided. If the RNN is bidirectional,\n",
       "          num_directions should be 2, else it should be 1.\n",
       "\n",
       "    Outputs: output, h_n\n",
       "        - **output** of shape `(seq_len, batch, num_directions * hidden_size)`: tensor\n",
       "          containing the output features (`h_t`) from the last layer of the RNN,\n",
       "          for each `t`.  If a :class:`torch.nn.utils.rnn.PackedSequence` has\n",
       "          been given as the input, the output will also be a packed sequence.\n",
       "\n",
       "          For the unpacked case, the directions can be separated\n",
       "          using ``output.view(seq_len, batch, num_directions, hidden_size)``,\n",
       "          with forward and backward being direction `0` and `1` respectively.\n",
       "          Similarly, the directions can be separated in the packed case.\n",
       "        - **h_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
       "          containing the hidden state for `t = seq_len`.\n",
       "\n",
       "          Like *output*, the layers can be separated using\n",
       "          ``h_n.view(num_layers, num_directions, batch, hidden_size)``.\n",
       "\n",
       "    Shape:\n",
       "        - Input1: :math:`(L, N, H_{in})` tensor containing input features where\n",
       "          :math:`H_{in}=\\text{input\\_size}` and `L` represents a sequence length.\n",
       "        - Input2: :math:`(S, N, H_{out})` tensor\n",
       "          containing the initial hidden state for each element in the batch.\n",
       "          :math:`H_{out}=\\text{hidden\\_size}`\n",
       "          Defaults to zero if not provided. where :math:`S=\\text{num\\_layers} * \\text{num\\_directions}`\n",
       "          If the RNN is bidirectional, num_directions should be 2, else it should be 1.\n",
       "        - Output1: :math:`(L, N, H_{all})` where :math:`H_{all}=\\text{num\\_directions} * \\text{hidden\\_size}`\n",
       "        - Output2: :math:`(S, N, H_{out})` tensor containing the next hidden state\n",
       "          for each element in the batch\n",
       "\n",
       "    Attributes:\n",
       "        weight_ih_l[k]: the learnable input-hidden weights of the k-th layer,\n",
       "            of shape `(hidden_size, input_size)` for `k = 0`. Otherwise, the shape is\n",
       "            `(hidden_size, num_directions * hidden_size)`\n",
       "        weight_hh_l[k]: the learnable hidden-hidden weights of the k-th layer,\n",
       "            of shape `(hidden_size, hidden_size)`\n",
       "        bias_ih_l[k]: the learnable input-hidden bias of the k-th layer,\n",
       "            of shape `(hidden_size)`\n",
       "        bias_hh_l[k]: the learnable hidden-hidden bias of the k-th layer,\n",
       "            of shape `(hidden_size)`\n",
       "\n",
       "    .. note::\n",
       "        All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
       "        where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
       "\n",
       "    .. include:: cudnn_persistent_rnn.rst\n",
       "\n",
       "    Examples::\n",
       "\n",
       "        >>> rnn = nn.RNN(10, 20, 2)\n",
       "        >>> input = torch.randn(5, 3, 10)\n",
       "        >>> h0 = torch.randn(2, 3, 20)\n",
       "        >>> output, hn = rnn(input, h0)\n",
       "    \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonlinearity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nonlinearity'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tanh'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonlinearity\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tanh'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'RNN_TANH'\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonlinearity\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'RNN_RELU'\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown nonlinearity '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\jacob\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RNN??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_classifer = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_Jul</th>\n",
       "      <th>Month_June</th>\n",
       "      <th>Month_Mar</th>\n",
       "      <th>Month_May</th>\n",
       "      <th>Month_Nov</th>\n",
       "      <th>Month_Oct</th>\n",
       "      <th>Month_Sep</th>\n",
       "      <th>VisitorType_Other</th>\n",
       "      <th>VisitorType_Returning_Visitor</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0             0.0                      0.0            0.0   \n",
       "1             0.0                      0.0            0.0   \n",
       "2             0.0                      0.0            0.0   \n",
       "3             0.0                      0.0            0.0   \n",
       "4             0.0                      0.0            0.0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0        0.001418                 0.000000   \n",
       "1                     0.0        0.002837                 0.001000   \n",
       "2                     0.0        0.001418                 0.000000   \n",
       "3                     0.0        0.002837                 0.000042   \n",
       "4                     0.0        0.014184                 0.009809   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay  ...  Month_Jul  Month_June  \\\n",
       "0         1.00       1.00         0.0         0.0  ...        0.0         0.0   \n",
       "1         0.00       0.50         0.0         0.0  ...        0.0         0.0   \n",
       "2         1.00       1.00         0.0         0.0  ...        0.0         0.0   \n",
       "3         0.25       0.70         0.0         0.0  ...        0.0         0.0   \n",
       "4         0.10       0.25         0.0         0.0  ...        0.0         0.0   \n",
       "\n",
       "   Month_Mar  Month_May  Month_Nov  Month_Oct  Month_Sep  VisitorType_Other  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0                0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0                0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0                0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0                0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0                0.0   \n",
       "\n",
       "   VisitorType_Returning_Visitor  Revenue  \n",
       "0                            1.0        0  \n",
       "1                            1.0        0  \n",
       "2                            1.0        0  \n",
       "3                            1.0        0  \n",
       "4                            1.0        0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Revenue',axis=1)\n",
    "y = df.Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_Feb</th>\n",
       "      <th>Month_Jul</th>\n",
       "      <th>Month_June</th>\n",
       "      <th>Month_Mar</th>\n",
       "      <th>Month_May</th>\n",
       "      <th>Month_Nov</th>\n",
       "      <th>Month_Oct</th>\n",
       "      <th>Month_Sep</th>\n",
       "      <th>VisitorType_Other</th>\n",
       "      <th>VisitorType_Returning_Visitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11898</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.062817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008511</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029787</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7647</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.241582</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078014</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053586</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10749</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.058968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009929</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043972</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1288</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055319</td>\n",
       "      <td>0.018267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9247 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Administrative  Administrative_Duration  Informational  \\\n",
       "4079         0.000000                 0.000000       0.000000   \n",
       "11898        0.074074                 0.062817       0.000000   \n",
       "2455         0.000000                 0.000000       0.000000   \n",
       "11581        0.000000                 0.000000       0.000000   \n",
       "7647         0.370370                 0.241582       0.041667   \n",
       "...               ...                      ...            ...   \n",
       "1061         0.000000                 0.000000       0.000000   \n",
       "10749        0.518519                 0.058968       0.000000   \n",
       "3419         0.000000                 0.000000       0.000000   \n",
       "1288         0.037037                 0.000000       0.000000   \n",
       "12305        0.000000                 0.000000       0.000000   \n",
       "\n",
       "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "4079                      0.0        0.004255                 0.000141   \n",
       "11898                     0.0        0.008511                 0.001703   \n",
       "2455                      0.0        0.029787                 0.009131   \n",
       "11581                     0.0        0.001418                 0.000000   \n",
       "7647                      0.0        0.078014                 0.037528   \n",
       "...                       ...             ...                      ...   \n",
       "1061                      0.0        0.004255                 0.000188   \n",
       "10749                     0.0        0.009929                 0.001132   \n",
       "3419                      0.0        0.043972                 0.016991   \n",
       "1288                      0.0        0.024113                 0.020544   \n",
       "12305                     0.0        0.055319                 0.018267   \n",
       "\n",
       "       BounceRates  ExitRates  PageValues  SpecialDay  ...  Month_Feb  \\\n",
       "4079      0.333333   0.666667    0.000000         0.0  ...        0.0   \n",
       "11898     0.000000   0.125000    0.000000         0.0  ...        0.0   \n",
       "2455      0.000000   0.035714    0.000000         0.0  ...        0.0   \n",
       "11581     1.000000   1.000000    0.000000         0.0  ...        0.0   \n",
       "7647      0.000000   0.053586    0.002712         0.0  ...        0.0   \n",
       "...            ...        ...         ...         ...  ...        ...   \n",
       "1061      0.000000   0.333333    0.000000         0.0  ...        0.0   \n",
       "10749     0.000000   0.023810    0.000000         0.0  ...        0.0   \n",
       "3419      0.000000   0.033333    0.000000         0.0  ...        0.0   \n",
       "1288      0.229167   0.500000    0.000000         0.0  ...        0.0   \n",
       "12305     0.000000   0.045322    0.000000         0.0  ...        0.0   \n",
       "\n",
       "       Month_Jul  Month_June  Month_Mar  Month_May  Month_Nov  Month_Oct  \\\n",
       "4079         0.0         0.0        0.0        1.0        0.0        0.0   \n",
       "11898        0.0         0.0        0.0        0.0        0.0        0.0   \n",
       "2455         0.0         0.0        0.0        1.0        0.0        0.0   \n",
       "11581        0.0         0.0        0.0        0.0        0.0        0.0   \n",
       "7647         0.0         0.0        0.0        0.0        1.0        0.0   \n",
       "...          ...         ...        ...        ...        ...        ...   \n",
       "1061         0.0         0.0        1.0        0.0        0.0        0.0   \n",
       "10749        0.0         0.0        0.0        0.0        0.0        0.0   \n",
       "3419         0.0         0.0        0.0        1.0        0.0        0.0   \n",
       "1288         0.0         0.0        1.0        0.0        0.0        0.0   \n",
       "12305        0.0         0.0        0.0        0.0        1.0        0.0   \n",
       "\n",
       "       Month_Sep  VisitorType_Other  VisitorType_Returning_Visitor  \n",
       "4079         0.0                0.0                            1.0  \n",
       "11898        0.0                0.0                            0.0  \n",
       "2455         0.0                0.0                            1.0  \n",
       "11581        0.0                1.0                            0.0  \n",
       "7647         0.0                0.0                            1.0  \n",
       "...          ...                ...                            ...  \n",
       "1061         0.0                0.0                            1.0  \n",
       "10749        0.0                1.0                            0.0  \n",
       "3419         0.0                0.0                            1.0  \n",
       "1288         0.0                0.0                            1.0  \n",
       "12305        0.0                0.0                            1.0  \n",
       "\n",
       "[9247 rows x 26 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_classifer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9033409017191047"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_classifer.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb_classifer.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clas_report = classification_report(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      2628\n",
      "           1       0.70      0.61      0.65       455\n",
      "\n",
      "    accuracy                           0.90      3083\n",
      "   macro avg       0.82      0.78      0.80      3083\n",
      "weighted avg       0.90      0.90      0.90      3083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lgb_clas_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8871229322088875"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_y_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_clas_report = classification_report(log_y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94      2916\n",
      "           1       0.30      0.82      0.44       167\n",
      "\n",
      "    accuracy                           0.89      3083\n",
      "   macro avg       0.64      0.86      0.69      3083\n",
      "weighted avg       0.95      0.89      0.91      3083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(log_reg_clas_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
